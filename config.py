"""
Configuration file for the PDF Q&A System
Auto-generated by model_selector.py
"""

# QA Engine Configuration
QA_CONFIG = {
    # Mode: 'extractive' (fast, accurate, uses regex) or 'generative' (slower, uses AI)
    'mode': 'extractive' if 'extractive' == 'extractive' else 'advanced',

    # Use advanced QA model (requires more memory but better accuracy)
    'use_advanced_qa': False,

    # Advanced QA model to use if use_advanced_qa=True
    'advanced_qa_model': 'extractive',

    # Use full document context instead of just top chunks (better accuracy)
    'use_full_context': True,

    # Number of top chunks to retrieve (only used if use_full_context=False)
    'top_k_chunks': 10,

    # Maximum answer length
    'max_answer_length': 3000,
}

# Embedding Model Configuration
EMBEDDING_CONFIG = {
    'model_name': 'all-MiniLM-L6-v2',
}

# Generator Model Configuration
GENERATOR_CONFIG = {
    'model_name': 'none',
    'use_generator': False,
}

# PDF Processing Configuration
PDF_CONFIG = {
    'chunk_size': 400,  # words per chunk
    'chunk_overlap': 50,  # overlapping words between chunks
}

# Flask Configuration
FLASK_CONFIG = {
    'host': '0.0.0.0',
    'port': 5000,
    'debug': True,
    'max_content_length': 16 * 1024 * 1024,  # 16MB
}
